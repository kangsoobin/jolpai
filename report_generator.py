from langchain.prompts import PromptTemplate
#from rag_engine.llm import load_llm
from rag_engine.embedder import get_embedder
from rag_engine.vector_store import load_vector_db, add_to_vector_db
from rag_engine.search import search_serper
from transformers import AutoTokenizer
from langchain.schema import Document
import uuid
import json
from typing import List, Optional
from fastapi import UploadFile, FastAPI, HTTPException, Header
from rag_engine.prompt import get_search_prompt
from rag_engine.loader import load_pdf
import requests
from fastapi import FastAPI, Form
from pydantic import BaseModel
import os
from dotenv import load_dotenv
from rag_engine.process import process_multiple_files
from rag_engine.tagger import generate_keyword_tags
from rag_engine.captioner import generate_captions
import io, base64, uuid, os

load_dotenv()
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

def call_claude(prompt: str, max_tokens: int = 512) -> str:
    url = "https://api.anthropic.com/v1/messages"
    headers = {
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
    }
    payload = {
        "model": "claude-3-5-sonnet-20241022",
        "max_tokens": max_tokens,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }
    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    return response.json()["content"][0]["text"]



def generate_report(
    topic: str,
    file: Optional[UploadFile] = None,
    file_paths: Optional[List[str]] = None,
    references: Optional[List[str]] = None,
):
    print("ğŸ“Œ 1. í•¨ìˆ˜ ì§„ì… - topic:", topic)
    docs = []
    # 1. PDF ì—…ë¡œë“œ â†’ ì €ì¥
    if file is not None:
        print("ğŸ“Œ 2. íŒŒì¼ ì €ì¥ ì‹œì‘ - filename:", file.filename)
        save_dir = os.path.join(os.getcwd(), "data")
        os.makedirs(save_dir, exist_ok=True)
        filename = f"{uuid.uuid4().hex}_{file.filename}"
        file_path = os.path.join(save_dir, filename)

        with open(file_path, "wb") as f:
            f.write(file.file.read())
        print("âœ… 3. íŒŒì¼ ì €ì¥ ì™„ë£Œ - path:", file_path)

        # 2. PDF â†’ ë¬¸ì„œ ë¶„í• 
        pages = load_pdf(file_path)
        print("âœ… 4. PDF ë¡œë”© ì™„ë£Œ - pages:", len(pages))
        docs = [
            Document(page_content=page.page_content, metadata={"source": filename, "page": i})
            for i, page in enumerate(pages)
        ]
    if file_paths:
        process_multiple_files(file_paths) 

    # 3. ë²¡í„° DBì— ì„ë² ë”©
    embedder = get_embedder()
    vectordb = load_vector_db(embedder)
    if docs:
        add_to_vector_db(docs, vectordb)
        print("âœ… 5. ë²¡í„° DB ì¶”ê°€ ì™„ë£Œ")


    # 4. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰(ë‚´ë¶€ê²€ìƒ‰)
    retriever = vectordb.as_retriever()
    internal_docs = retriever.get_relevant_documents(topic)
    
    # ì™¸ë¶€ ê²€ìƒ‰ (Serper)
    external_docs = search_serper(topic, num_results=3)

    # 6. ë¬¸ì„œ í†µí•© ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±ì„±
    # all_docs = internal_docs + external_docs
    all_docs = internal_docs
    context = "\n\n".join([doc.page_content for doc in all_docs])
    print("âœ… 6. ë¬¸ì„œ í†µí•© ì™„ë£Œ - ë¬¸ì„œ ìˆ˜:", len(all_docs))

    # 5. referencesê°€ ìˆë‹¤ë©´ ë¬¸ë§¥ ë’·ë¶€ë¶„ì— ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ë¶™ì´ê¸°
    if references:
        requirements_text = "\n\n[ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­]\n" + "\n".join(references)
        context += requirements_text

    prompt_template = get_search_prompt() #-> completioní˜¸ì¶œ ë°©ì‹ë•Œ ê²Ÿì„œì¹˜ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜
    full_prompt = prompt_template.format(context=context, question=topic)
    print("ğŸ“Œ 7. í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

   
    # llm = load_llm()

    # âœ… í† í° ìˆ˜ ì²´í¬ ë° ìë¥´ê¸°
    # prompt_tokens = llm.tokenize(full_prompt.encode("utf-8"), add_bos=True)
    # if len(prompt_tokens) > 2048:
    #     print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. {len(prompt_tokens)} â†’ 2048ë¡œ ìë¦…ë‹ˆë‹¤.")
    #     prompt_tokens = prompt_tokens[:2048]
    #     full_prompt = llm.detokenize(prompt_tokens).decode("utf-8")

    # # âœ… ëª¨ë¸ í˜¸ì¶œ
    # try:
    #     output = llm(
    #         prompt=full_prompt,
    #         max_tokens=512,
    #         stop=["<|eot_id|>"],
    #         echo=False
    #     )["choices"][0]["text"]
    #     print("ğŸ’¬ llama.cpp ëª¨ë¸ ì‘ë‹µ ë„ì°©")
    # except Exception as e:
    #     import traceback
    #     print("âŒ llama.cpp ëª¨ë¸ invoke ì‹¤íŒ¨:")
    #     traceback.print_exc()
    #     output = None
    
    # âœ… Claude APIë¡œ ê¸°ì‚¬ ë³¸ë¬¸ ìƒì„±
    try:
        output = call_claude(full_prompt, max_tokens=8000)
        print("ğŸ’¬ Claude ì‘ë‹µ ë„ì°©")
    except Exception as e:
        import traceback
        print("âŒ Claude API í˜¸ì¶œ ì‹¤íŒ¨:")
        traceback.print_exc()
        output = None


    if output:
        title_prompt = f"""
        ë‹¹ì‹ ì€ ìŠ¤í¬ì¸  ê¸°ì‚¬ ì œëª© ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” **ê¸°ì‚¬ ì œëª©**ì„ í•œ ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”.(15~20ì ì´ë‚´ ê¶Œì¥)
        
        [ì¶œë ¥ í˜•ì‹]
        "ì œëª©"

        ê¸°ì‚¬ ë‚´ìš©:
        {output.strip()}
        """
        try:
            title_output = call_claude(title_prompt, max_tokens=64).strip()
            print("ğŸ“ ê¸°ì‚¬ ì œëª© ìƒì„± ì™„ë£Œ:", title_output)
        except Exception as e:
            title_output = "ê¸°ì‚¬ ì œëª© ìƒì„± ì‹¤íŒ¨"
            print("âŒ ì œëª© ìƒì„± ì˜¤ë¥˜:", e)
    else:
        title_output = "ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨ë¡œ ì œëª© ì—†ìŒ"
        
    #  íƒœê·¸ ìƒì„± (LLM ì½œë°±ìœ¼ë¡œ call_claude ì£¼ì…)
    if output:
        try:
            print("ğŸ¯ íƒœê·¸ ìƒì„± ì‹œì‘ - article ê¸¸ì´:", len(output), "topic:", topic)
            tags = generate_keyword_tags(
                article=output,
                topic=topic,
                llm_fn=lambda p, mt: call_claude(p, max_tokens=mt),  # â† ì˜ì¡´ì„± ì£¼ì…
                max_tags=12
            )
            print("ğŸ·ï¸ íƒœê·¸ ìƒì„± ì™„ë£Œ:", tags, "(íƒ€ì…:", type(tags), "ê¸¸ì´:", len(tags), ")")
        except Exception as e:
            print("âŒ íƒœê·¸ ìƒì„± ì‹¤íŒ¨:", e)
            import traceback
            traceback.print_exc()
            tags = []
    else:
        print("âŒ outputì´ ì—†ì–´ì„œ íƒœê·¸ ìƒì„± ê±´ë„ˆëœ€")
        tags = []
        
    # íŠ¸ìœ—ìƒì„±
    if output:
        try:
            captions = generate_captions(
                article=output,
                topic=topic,
                llm_fn=lambda p, mt: call_claude(p, max_tokens=mt),
           )
            print("ğŸª„ ìº¡ì…˜ ìƒì„± ì™„ë£Œ:", captions)
        except Exception as e:
            print("âŒ ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨:", e)
            captions = {}
    else:
        captions = {}


    # 9. ì¶œì²˜ ìˆ˜ì§‘
    sources = [doc.metadata.get("source") for doc in all_docs if "source" in doc.metadata]



    # 10. JSON í˜•íƒœë¡œ ë°˜í™˜
    result = {
        "user_request": f"{topic}",
        "title": title_output,
        "content": output.strip(),
        "sources": sources,
        "tags": tags,
        "captions": captions,
    }
    print("ğŸ“¦ ìµœì¢… ë°˜í™˜ ê²°ê³¼:")
    print(f"  - title: {result['title']}")
    print(f"  - content ê¸¸ì´: {len(result['content'])}")
    print(f"  - sources: {result['sources']}")
    print(f"  - tags: {result['tags']} (íƒ€ì…: {type(result['tags'])}, ê¸¸ì´: {len(result['tags'])})")
    print(f"  - captions: {result['captions']}")
    return result



# # API ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
# class GenerateReportRequest(BaseModel):
#     prompt: str

# class GenerateReportResponse(BaseModel):
#     title: str
#     content: str
#     sources: List[str]

    
# # FastAPI ë¼ìš°í„°
# app = FastAPI(title="AI Report Generator API")

# @app.post("/generate_report", response_model=GenerateReportResponse)
# async def generate_report_api(prompt: str = Form(...)):
#     report = generate_report(prompt)
#     return GenerateReportResponse(**report)  # âœ… ì–¸íŒ©í•´ì„œ ë”± ë§ê²Œ ì „ë‹¬


if __name__ == "__main__":
    topic = input(" ê¸°ì‚¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    report = generate_report(topic, file=None, references=None)
    print("\nğŸ“„ ê¸°ì‚¬ ìš”êµ¬ì‚¬í•­:")
    print(report["user_request"])
    print("\nğŸ“° ê¸°ì‚¬ ì œëª©:")
    print(report["title"])
    print("\nğŸ“ ê¸°ì‚¬ ë‚´ìš©:")
    print(report["content"])
    print("\nğŸ·ï¸ íƒœê·¸:")
    tags = report.get("tags", [])
    if tags:
        print(", ".join(tags))
    else:
        print("(íƒœê·¸ ì—†ìŒ)")
    print("\nğŸª„ íŠ¸ìœ—:")
    captions = report.get("captions", {})
    if captions:
        print(f"  [X] {captions.get('x', '(ì—†ìŒ)')}")
        print(f"  [Kakao] {captions.get('kakao', '(ì—†ìŒ)')}")
    else:
        print("(ìº¡ì…˜ ì—†ìŒ)")
    print("\nğŸ”— ì°¸ê³  ì¶œì²˜:")
    for src in report["sources"]:
        print("-", src)
        



